<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <title>
        Diffusion Model - RitzzzZ 
    </title>
     
    
<link rel="stylesheet" href="/css/grid.css">

    
<link rel="stylesheet" href="/css/custom.css">

    
<link rel="stylesheet" href="/css/ringo.css">

     
        <link rel="icon" type="image/x-icon" href="/img/icon.png " />
     
     
     
        <meta name=" " content="" />
     
        <meta name=" " content="" />
     
 
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

  <body>
    <header id="header" class="clearfix" onclick="window.open('/', '_self')">
    <div class="site-name">
        <a href="/" id="logo" class="site-title">
            RitzzzZ
        </a>
        <p class="description site-description">
            <span style="padding-top:20px; font-size: 10px">
                An infinite journey
            </span>
        </p>
    </div>
</header>
<div id="sidebar" role="complementary">
    <section class="widget">
        <ul class="menu widget-list">
            
                <li class="menu-item">
                    <a href="/" class="menu-item-link">
                        Home
                    </a>
                </li>
                
                <li class="menu-item">
                    <a href="/about" class="menu-item-link">
                        About
                    </a>
                </li>
                
                <li class="menu-item">
                    <a href="/archives" class="menu-item-link">
                        Archives
                    </a>
                </li>
                
        </ul>
    </section>
    <section class="widget sidebar-foot">
        <ul class="widget-list">
            <li>Theme <a rel="nofollow" target="_blank" href="https://github.com/HeliumOI/hexo-theme-ringo">Ringo</a>
                by <a target="_blank" href="/ "> RitzzzZ  </a></li>
            <li>Proudly powered by  <a rel="nofollow" target="_blank" href="https://hexo.io/">Hexo</a></li>
        </ul>
    </section>
</div>

<div id="helpbar">
    <div class="back-to-top">
        <button id="back2top">↑</button>
        <script>
            back2top.onclick = function() {
                var movement = document.body.scrollTop || document.documentElement.scrollTop;
                scrollBy(0, -movement);
            }
        </script>
    </div>
</div>
      <main class="main">
        <div id="body">
          <div class="container">
            <div class="col-12" id="main" role="main">
    <article class="post post-atpost" itemscope itemtype="http://schema.org/BlogPosting">
        <div class="post-title">
            <h1 class="post-title post-title-atpage" itemprop="name headline">
                <a itemprop="url" href="/2023/08/01/Diffusion-Model/">
                    Diffusion Model
                </a>
            </h1>
        </div>
        <ul class="post-meta post-meta-atpage">
            <li class="post-time">
                2023-08-01
            </li>
            <li>
                <div class="article-category">
                    
                </div>
            </li>
        </ul>
        <div class="post-content" itemprop="articleBody">
            <blockquote>
<p>论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.11239.pdf">Denoising Diffusion Probabilistic Model (DDPM)</a></p>
</blockquote>
<h2 id="DDPM原文阅读"><a href="#DDPM原文阅读" class="headerlink" title="DDPM原文阅读"></a>DDPM原文阅读</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>Diffusion Model是一种Markov chain，也就是说t时刻的值只依赖于前一个时刻t-1的值。</p>
<p><img src="200.png" alt="Untitled"></p>
<p>逆向过程：$x_T \to x_0$ 从高斯噪声一步步denoise生成图像的过程。</p>
<p><img src="201.png" alt="Untitled"></p>
<p>正向/扩散过程：$x_0 \to x_T$ 在图像上逐渐加噪声，经过T步后变成纯噪声。</p>
<p><img src="202.png" alt="Untitled"></p>
<p>等价于下面这种写法，即第t步的图像等于t-1步的图像和采样的噪声的加权。</p>
<script type="math/tex; mode=display">
x_t=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}\epsilon_t,\epsilon_t \sim \mathcal N(0,I)</script><p>由于马尔科夫链的性质，每一步加噪过程都是独立的，已知 $x_0$ 就可以直接计算得到 $x_t$ 。</p>
<p><img src="203.png" alt="Untitled"></p>
<p>推导过程：</p>
<script type="math/tex; mode=display">
\alpha_t:=1-\beta_t,\bar\alpha_t:=\prod\limits_{i=1}^t{\alpha_i} \\ \begin{align*} x_t &=\sqrt{\alpha_t}x_{t-1}+\sqrt{\beta_t}\epsilon_t \\&=\sqrt{\alpha_t}  (\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{\beta_{t-1}}\epsilon_{t-1})  +\sqrt{\beta_t}\epsilon_t \\&=...\\&=\sqrt{\alpha_t}...\sqrt{\alpha_1}x_0+\sqrt{1-\bar\alpha_t}\epsilon\\&=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\epsilon\\& \sim \mathcal N (x_t;\sqrt{\bar \alpha_t}x_0, (1-\bar \alpha_t) I)\end{align*}</script><h3 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h3><p>目标：生成的图像的分布近似于数据集中的图像分布</p>
<p>Negative log likelihood：</p>
<p><img src="204.png" alt="Untitled"></p>
<p>改写成KL散度：q是在已知 $x_0$ 条件下的后验概率，$p_\theta$ 是要求的不知道 $x_0$ 的后验概率，优化KL散度来使得 $p_\theta$ 逼近 q。</p>
<p><img src="205.png" alt="Untitled"></p>
<p>当 $x_0$ 已知时，可以得到：</p>
<p><img src="206.png" alt="Untitled"></p>
<p><strong>采样是不可导的</strong>，为了解决这个问题，进行<strong>重参数化</strong>（构造一个新的随机变量，把采样和参数分开）。</p>
<p>预测噪声而不是预测分布的均值，进一步简化为以下形式：</p>
<p><img src="207.png" alt="Untitled"></p>
<p>最终的目标函数：</p>
<p><img src="208.png" alt="Untitled"></p>
<h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>用神经网络 $\epsilon_\theta$ 预测噪声，loss function：</p>
<script type="math/tex; mode=display">
L_2=||\epsilon_t-\epsilon_\theta(x_t,t)||^2</script><p><img src="209.png" alt="Untitled"></p>
<p>训练：正向过程每一步加的噪声都是已知的，把加了噪声的图片和t输入predictor，输出预测的噪声，和正向过程中加上的噪声计算L2 loss，梯度下降方式更新网络参数。</p>
<p>采样：从一幅噪声开始，经过T步去噪生成图像。每一步从 $x_t$ 减去预测的噪声，并采样一个噪声z，得到 $x_{t-1}$。t = 1时不用加噪音z，因为下一步要输出结果 $x_0$ 。</p>
<p><img src="2010.png" alt="Untitled"></p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>正向过程的方差设定为常数，线性增长：$\beta_1=10^{-4},\beta_T=0.02$</p>
<p>逆向过程：U-Net backbone，position embedding，self-attention</p>
<p><strong>生成图片质量</strong></p>
<p><img src="2011.png" alt="Untitled"></p>
<p><strong>消融实验</strong>：逆向过程中，使用简化的目标函数，预测均值的训练效果很差，预测噪声的表现好很多；用variational bound作为目标函数时，预测均值和预测噪声的表现差不多。</p>
<p><img src="2012.png" alt="Untitled"></p>
<p>可学习的逆向过程方差会导致训练不稳定。</p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p><a target="_blank" rel="noopener" href="https://github.com/zoubohao/DenoisingDiffusionProbabilityModel-ddpm-/blob/main/">简化的PyTorch实现</a></p>
<h2 id="拓展工作：DDIM"><a href="#拓展工作：DDIM" class="headerlink" title="拓展工作：DDIM"></a>拓展工作：DDIM</h2><p>目标：加速DDPM</p>
<p>方法：假设期望满足分布</p>
<script type="math/tex; mode=display">
p(x_{t-1}|x_t,x_0) \sim \mathcal N (kx_0+mx_t,\sigma^2 I)</script><p>可以不连续地进行推理（不需要马尔可夫假设），跳过中间一些步；整个推导过程和方差无关。</p>
<p><img src="2013.png" alt="Untitled"></p>
<h2 id="Appendix：生成模型"><a href="#Appendix：生成模型" class="headerlink" title="Appendix：生成模型"></a>Appendix：生成模型</h2><p>两堆样本，一堆是真实样本，另一堆是我们生成的样本</p>
<ol>
<li>一一对应：diffusion/VAE</li>
<li>把它们混在一起，看能不能分出来：GAN（因为不是一一对应的，所以很难训练</li>
</ol>
<blockquote>
<p>入门视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV14c411J7f2/?spm_id_from=333.337.search-card.all.click&amp;vd_source=dd883cce367009200a0a78c39490e160">Diffusion Model讲解 - 李宏毅 (2023)</a></p>
</blockquote>
<h2 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h2><p>Reverse Process: 从纯噪声开始，进行N步denoise，得到干净的图像</p>
<p>Denoise模块内部做了什么：Noise Predictor预测图像中的噪声，图片减去噪声得到输出</p>
<h3 id="如何训练Noise-Predictor？"><a href="#如何训练Noise-Predictor？" class="headerlink" title="如何训练Noise Predictor？"></a>如何训练Noise Predictor？</h3><ul>
<li>在图像的每一个step加入随机采样的噪声，就能得到加了噪声的图片</li>
<li>这个噪声在训练时被作为每一步Noise Predictor的GT</li>
<li>这个过程叫Forward Process/Diffusion Process</li>
</ul>
<p>Text-to-Image：在每个Denoise步骤中，输入加上一段文字描述；Noise Predictor工作过程可以由下图表示</p>
<p><img src="image1.png" alt="Alt text"></p>
<h2 id="深入理解算法"><a href="#深入理解算法" class="headerlink" title="深入理解算法"></a>深入理解算法</h2><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p><img src="image4.png" alt="Alt text"></p>
<ul>
<li>$\epsilon_\theta$是noise predictor，将带噪声的图和$t$作为这个函数的输入</li>
<li>实际上，不是每一步在前一步上加一点噪音，而是将clean image和噪声图做weighted sum</li>
<li>每一步的weight不同，随着$t$增大，噪声占比增大</li>
</ul>
<h3 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h3><p><img src="image7.png" alt="Alt text"></p>
<p><strong>Maximum Likelihood Estimation</strong>：衡量两个distribution的相似程度。在数据中采样，也就是在一堆训练集的图片中随机抽取一部分图片。我们要最大化的目标是$\theta^*=\arg\max \limits_\theta \prod\limits_{i=1}^mp_\theta(x^i)$，也就是要得到生成图像$x^i$的几率更大的分布。</p>
<p>为什么可以通过优化这个目标函数来使两个distribution更相似呢？以下推导证明maximize likelihood等价于minimize KL divergence，而KL divergence越小说明两个distribution越相似：</p>
<p><img src="image.png" alt="Alt text"></p>
<p>如何计算weight？</p>
<p><img src="image3.png" alt="Alt text"></p>
<p>如何最小化KL divergence？variance是固定的，所以我们在优化时要做的是让mean靠近目标distribution。</p>
<p>为什么需要sample？（即Algorithm 2中的$\sigma_t$项）如果不sample，只取几率最大的，那么每次生成的都是一样的内容。</p>
<ul>
<li>语音合成也要sampling，通过在inference time加入dropout层，将variance引入</li>
<li>Diffusion Model是一种autoregressive，加入一些随机性，结果才会好</li>
</ul>
<h2 id="完整的diffusion-model"><a href="#完整的diffusion-model" class="headerlink" title="完整的diffusion model"></a>完整的diffusion model</h2><p><img src="image5.png" alt="Alt text"></p>
<ul>
<li>text encoder：用来编码conditional text，一般是一个预训练好的模型；对结果影响很大（Imagen那篇文章进行了对比），好的text encoder可以帮助生成数据集中没有出现过的那些文字对应的图像</li>
<li>decoder：将中间产物（小图/latent representation）还原成所需大小的图片，可以单独训练，不需要带标签的训练集；如果中间产物是latent representation，可以训练一个auto-encoder，将图像映射到latent space，能够提高计算效率，因为diffusion model很吃计算资源</li>
<li>generation model：输入文字，输出图像，即text-to-image</li>
</ul>
<h3 id="常见的diffusion-model"><a href="#常见的diffusion-model" class="headerlink" title="常见的diffusion model"></a>常见的diffusion model</h3><ul>
<li>Stable Diffusion</li>
<li>DALL-E series (OpenAI)</li>
<li>Imagen (Google)</li>
<li>Parti</li>
</ul>
<h3 id="diffusion-vs-VAE"><a href="#diffusion-vs-VAE" class="headerlink" title="diffusion vs. VAE"></a>diffusion vs. VAE</h3><p><img src="image6.png" alt="Alt text"></p>
<p>VAE: lower bound of $\log P(x)$</p>
<p>DDPM: compute $P_\theta(x)$</p>
<p><img src="image2.png" alt="Alt text"></p>
<h2 id="Diffusion-Model在语音、文字领域"><a href="#Diffusion-Model在语音、文字领域" class="headerlink" title="Diffusion Model在语音、文字领域"></a>Diffusion Model在语音、文字领域</h2><h3 id="for-speech"><a href="#for-speech" class="headerlink" title="for speech"></a>for speech</h3><p>WaveGrad</p>
<h3 id="for-text"><a href="#for-text" class="headerlink" title="for text"></a>for text</h3><p>由于文字是离散的，很难加noise；解决方法是在latent space（比如word embedding）中加noise</p>
<ul>
<li>Diffusion-LM</li>
<li>DiffuSeq</li>
</ul>
<p>或者不加Gaussian noise，而是加mask。从这里介绍一类方法，Mask-Predict，运用在图像上时，叫Masked Visual Token Modeling (MVTM)</p>
<p><img src="image8.png" alt="Alt text"></p>
<ul>
<li>Training：先训练一个auto-encoder，可以将图像编码为latent representation，之后的一切处理都在latent representation上进行；把一些tokens变成masked tokens，训练一个predictor来预测完整的tokens。</li>
<li>Generation：全部都是masked tokens的图输入decoder，把一些confidence score低的tokens再加上mask，重新生图</li>
</ul>
<h2 id="图像评估指标"><a href="#图像评估指标" class="headerlink" title="图像评估指标"></a>图像评估指标</h2><p>FID：Frechet distance between the two Gaussians，值越小越好，假设两份采样是Guassians distribution</p>
<p>CLIP：Contrastive Language-Image Pre-Training，用400 million image-text pair训练出来的模型，CLIP score越大越好</p>

             
        </div>
        
            <p itemprop="keywords" class="tags">
                
                    <a href="/tags/CV/"> CV </a>
                
            </p>
        
    </article>
    <div class="post-near">
    <div class="post-near-child post-near-child-left "> 
        
            <a href="/2023/07/30/Probability/">Probability &laquo; </a>
        
        <br /> Prev  &laquo;
    </div>
    <div class="post-near-child post-near-child-right">
        
            <a href="/2023/08/03/Classic-Deep-Network/"> &raquo; Classic Deep Network</a>
        
        <br /> &raquo; Next 
    </div>
</div>
</div>
             
<div id="comments">
     
</div>
 
            <footer id="footer" role="contentinfo">
    
        &copy; 2022 - 2023
        <br />
    
    
    <br />
    
    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_value_site_pv">......</span> visits ·
        <span id="busuanzi_value_site_uv">......</span> visitors 
    
</footer>
          </div>
        </div>
      </main>
      <!-- highlight support -->

    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/styles/default.min.css">


<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/highlight.min.js"></script>
 
<script>
        hljs.initHighlightingOnLoad();
</script>
 
<!-- prettify support -->

    
<link rel="stylesheet" href="/prettify/prettify.css">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/color-themes-for-google-code-prettify@2.0.4/dist/themes/tomorrow.min.css">


<script src="/prettify/prettify.js"></script>


<script>
    let prettifyel = document.querySelectorAll('pre');
    for (let i = 0; i < (prettifyel || []).length; i += 1) {
        prettifyel[i].classList.add('prettyprint');
        prettifyel[i].classList.add('linenums');
    }
    PR.prettyPrint();
</script>
 
<!-- mathjax support -->

    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- fancybox support -->
 
<!-- viewerjs support -->

    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/viewerjs@1.10.0/dist/viewer.min.css">


<script src="https://cdn.jsdelivr.net/npm/viewerjs@1.10.0/dist/viewer.min.js"></script>

<script type="text/javascript">
    Viewer.setDefaults({
        zoomRatio: [0.5],
        show: function () {
            this.viewer.zoomTo(1);
        },
    });
    
    var imageList = document.querySelector('.post-content').getElementsByTagName('img');
    
    var imageArray = new Array();
    Array.prototype.forEach.call(imageList, element => {
        if (element.alt != "no-view" && element.className != "no-view") {
            imageArray.push(element);
        }
    });
    
    Array.prototype.forEach.call(imageArray, element => {
        var viewer1 = new Viewer(element);
        viewer1.images = imageArray;
        viewer1.length = imageArray.length;
    });
</script>
 
<!-- google analytics support -->



 
 

<!-- lazyload support -->

    
<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.4.0/dist/lazyload.min.js"></script>

<script>
    new LazyLoad({
        elements_selector: '.post-content img'
    });
</script>
 
  </body>

</html>